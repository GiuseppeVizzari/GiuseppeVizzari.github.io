---
title: 'Around-the-AI-act'
description: "Some considerations and thought on topics somehow related to the AI act"
date: 2023-12-17
permalink: /posts/2023/17/Around-the-AI-act/
tags:
  - AI
  - AI-act
  - copyright
  - EU
---

The so-called [AI Act has been agreed upon by the EU Parliament and member states](https://www.theguardian.com/world/2023/dec/08/eu-agrees-historic-deal-with-worlds-first-laws-to-regulate-ai). The news is about the formal agreement among these not necessarily aligned actors, more than the content of the regulation, which [still needs to be adopted by the Parliament and Council to be become EU law](https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai). Contents were in fact mostly defined beforehand, although some details, such as [exceptions to the regulations for national security, specific crimes, and military/defense systems](https://www.technologyreview.com/2023/12/11/1084942/five-things-you-need-to-know-about-the-eus-new-ai-act/) were defined in the last negotiation.

I haven't really read the bill in details (and details here are very important, but probably also not so simple to grasp), honestly, but I want to say something as a form of response to some comments that I read in several posts in my filter bubble, that is still relatively varied since I disagree with the above comments.

First of all, at least in Italy there are two clich√©s that are relevant to this case: (i) that __there is no European Google (or Microsoft, or Apple, or... insert your favorite big tech here)__, and (ii) __"laces and straps" (in italian _"lacci e lacciuoli"_)__ that essentially burden the capacity of our private sector to innovate. In this case, the two independent and self-sufficient heavily rhetorical arguments (that are essentially an __apparent (and unnecessarily stressed) truth__ and __a statement assumed as true that would instead be complicated to prove__) have a toxic synergy, suggesting that there would not be a big tech in the EU (and in Italy especially) due to the heavy regulation that represents a burden too heavy to allow European companies to fly as high as American or Asian ones.

Well, I beg to disagree.

It is surely true that __innovative sectors tend to be initially less regulated__, first of all since they are not immediately understood by law makers, governments, parliaments, just as the common men. This surely happened to the world wide web related economical activities. At least to a certain degree, __the lack of regulation might even be the result of a deliberated attempt to wait for the right moment to take decisions__, after the matter has been sufficiently understood, and after the economical potential, and the implications of the activities have been at least reasonably estimated.

In my opinion, __world wide web economical activities have been left without a proper regulation far too long__ and, if the above deliberation wad done by someone in the regulation process, it botched big time. Some of the __concerns that are now being expressed about generative AI models (either employing language and text, images, music, videos) are largely related to unsolved issues about copyright and fair use of digital contents, privacy, and eventually antitrust issues__. Of course, the magnitude of the implications of these problems has been deeply amplified, but roots pre-date the generative AI successes and maybe even their conception.

Just a small selection of old news:
- [Facebook's Cambridge Analytica scandal](https://arstechnica.com/tech-policy/2018/03/facebooks-cambridge-analytica-scandal-explained/) and (recent class-action setting)[https://arstechnica.com/information-technology/2022/12/meta-to-pay-725-million-to-settle-cambridge-analytica-lawsuit/], plus [related and unresolved issues about spreading propaganda](https://arstechnica.com/tech-policy/2017/10/facebook-google-and-twitter-tell-congress-they-spread-russian-propaganda/);
- a flurry of Google antirust related news: [French antitrust settlement](https://arstechnica.com/tech-policy/2021/06/google-will-pay-268m-revamp-ad-platform-to-settle-antitrust-claims/), [Maps dominance and restrictions from using competing services](https://arstechnica.com/gadgets/2022/03/googles-next-us-antitrust-issue-google-maps/), [civil antitrust suit for monopolizing digital advertising](https://arstechnica.com/tech-policy/2023/06/googles-ad-tech-dominance-spurs-more-antitrust-charges-report-says/), and the list could be a lot longer;
- [newspapers lawsuits against news clipping services](https://arstechnica.com/tech-policy/2013/03/newspapers-go-all-in-for-copyright-fight-against-clipping-service/?itm_source=parsely-api), more recently [Google and Facebook that struck a deal with Australian publishers to avoid restrictions to news](https://arstechnica.com/tech-policy/2021/02/big-tech-opens-wallet-for-publishers-as-australian-news-code-looms/), but the list could go on forever, and some old news are more complicated to retrieve due to the sheer number of more recent news.

More recent points are essentially repetitions of older stories, spiced up with generative AI:
- [lawsuit against Stability AI](https://arstechnica.com/tech-policy/2023/04/stable-diffusion-copyright-lawsuits-could-be-a-legal-earthquake-for-ai/), later [followed by another action by Getty](https://arstechnica.com/tech-policy/2023/02/getty-sues-stability-ai-for-copying-12m-photos-and-imitating-famous-watermark/) that however [wants to be part of the generative AI game, legally](https://arstechnica.com/tech-policy/2023/10/getty-images-built-a-socially-responsible-ai-tool-that-rewards-artists/);
- [New York Times that prohibits AI companies from scraping its content without permission](https://arstechnica.com/information-technology/2023/08/the-new-york-times-prohibits-ai-vendors-from-devouring-its-content/).

So, and maybe I'm just wearing a pair of _pink glasses_ that after all I also have, this might be the chance to __clean some serious dust we swept under a non-existing rug for far too long__. Also consider that having a somewhat clear regulatory framework might be even beneficial for companies considering the possibility to start some particular AI related business, since it should be a bit simpler to understand if there might be legal problems in the development of some line of work.

On the contrary, I want to warn against the __"move fast and break things"__ rhetoric and ideology: the above links are representatives of what did this line of action of hige private companies whose agenda might be worth discussing brought to the Internet ecosystem, even not getting to [experiments that went against ethical guidelines for informed consent carried out by Facebook](https://www.theguardian.com/technology/2014/jun/30/facebook-emotion-study-breached-ethical-guidelines-researchers-say).

I think that looking at these issues from a less partisan point of view, and with a perspective considering a bigger picture, looking at trajectories that started long ago, might be beneficial. A good read for the upcoming winter break might be [The Attention Merchants by Tim Wu](https://www.goodreads.com/book/show/28503628-the-attention-merchants) and [The Code of Capital by Katharina Pistor](https://www.goodreads.com/book/show/42585103-the-code-of-capital?ref=nav_sb_ss_1_12), both from Columbia Law School, also to understand that __we might have preconceptions about lawyers, rules, and regulations, but at the end of the road we desperately need good laws, rules, and regulations__.



